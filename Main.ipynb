{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Langues √† reconna√Ætre\n",
    "languages = ['francais', 'italien', 'allemande', 'russe', '']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction am√©lior√©e des caract√©ristiques : MFCC + delta + delta-delta + suppression silence\n",
    "def extract_features(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    y_trimmed, _ = librosa.effects.trim(y, top_db=20)\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(y=y_trimmed, sr=sr, n_mfcc=13)\n",
    "    delta = librosa.feature.delta(mfcc)\n",
    "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "\n",
    "    features = np.vstack([mfcc, delta, delta2]).T  # shape (n_frames, 39)\n",
    "\n",
    "    # Normalisation\n",
    "    scaler = StandardScaler()\n",
    "    features = scaler.fit_transform(features)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du dataset\n",
    "def load_dataset(dataset_path):\n",
    "    X, y = [], []\n",
    "    for label in languages:\n",
    "        class_path = os.path.join(dataset_path, label)\n",
    "        for file in os.listdir(class_path):\n",
    "            if file.endswith(\".wav\"):\n",
    "                try:\n",
    "                    features = extract_features(os.path.join(class_path, file))\n",
    "                    X.append(features)\n",
    "                    y.append(label)\n",
    "                except Exception as e:\n",
    "                    print(f\"[ERREUR] {file} ignor√© ({e})\")\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entra√Ænement des mod√®les GMM\n",
    "def train_gmm_models(X_train, y_train, n_components=16):\n",
    "    models = {}\n",
    "    for lang in languages:\n",
    "        features = np.vstack([x for x, y in zip(X_train, y_train) if y == lang])\n",
    "        gmm = GaussianMixture(n_components=n_components, covariance_type='diag', max_iter=200, random_state=0)\n",
    "        gmm.fit(features)\n",
    "        models[lang] = gmm\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©diction par log-vraisemblance maximale\n",
    "def predict(models, X):\n",
    "    predictions = []\n",
    "    for features in X:\n",
    "        scores = {lang: model.score(features) for lang, model in models.items()}\n",
    "        best_lang = max(scores, key=scores.get)\n",
    "        predictions.append(best_lang)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gmm_models(models, save_dir=\"models_gmm\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    for lang, gmm in models.items():\n",
    "        # Sauvegarder chaque attribut s√©par√©ment\n",
    "        np.save(os.path.join(save_dir, f\"{lang}_means.npy\"), gmm.means_)\n",
    "        np.save(os.path.join(save_dir, f\"{lang}_covariances.npy\"), gmm.covariances_)\n",
    "        np.save(os.path.join(save_dir, f\"{lang}_weights.npy\"), gmm.weights_)\n",
    "        np.save(os.path.join(save_dir, f\"{lang}_precisions_cholesky.npy\"), gmm.precisions_cholesky_)\n",
    "        print(f\"‚úÖ Mod√®le {lang} sauvegard√© dans {save_dir}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des donn√©es...\n"
     ]
    }
   ],
   "source": [
    "print(\"Chargement des donn√©es...\")\n",
    "X_train, y_train = load_dataset(\"dataset_cv - Copie/train\")\n",
    "X_val, y_val = load_dataset(\"dataset_cv - Copie/validation\")\n",
    "X_test, y_test = load_dataset(\"dataset_cv - Copie/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Entra√Ænement des GMMs avec 8 composantes...\n",
      "üìä √âvaluation sur la validation :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   allemande      0.625     0.721     0.670       104\n",
      "    francais      0.808     0.567     0.667       104\n",
      "     italien      0.684     0.769     0.724       104\n",
      "       russe      0.689     0.702     0.695       104\n",
      "\n",
      "    accuracy                          0.690       416\n",
      "   macro avg      0.701     0.690     0.689       416\n",
      "weighted avg      0.701     0.690     0.689       416\n",
      "\n",
      "üìä √âvaluation sur le test :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   allemande      0.639     0.745     0.688       204\n",
      "    francais      0.819     0.578     0.678       204\n",
      "     italien      0.656     0.711     0.682       204\n",
      "       russe      0.681     0.711     0.695       204\n",
      "\n",
      "    accuracy                          0.686       816\n",
      "   macro avg      0.699     0.686     0.686       816\n",
      "weighted avg      0.699     0.686     0.686       816\n",
      "\n",
      "\n",
      "üîÅ Entra√Ænement des GMMs avec 16 composantes...\n",
      "üìä √âvaluation sur la validation :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   allemande      0.658     0.760     0.705       104\n",
      "    francais      0.805     0.596     0.685       104\n",
      "     italien      0.727     0.769     0.748       104\n",
      "       russe      0.679     0.712     0.695       104\n",
      "\n",
      "    accuracy                          0.709       416\n",
      "   macro avg      0.717     0.709     0.708       416\n",
      "weighted avg      0.717     0.709     0.708       416\n",
      "\n",
      "üìä √âvaluation sur le test :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   allemande      0.652     0.725     0.687       204\n",
      "    francais      0.830     0.623     0.711       204\n",
      "     italien      0.727     0.784     0.755       204\n",
      "       russe      0.722     0.765     0.743       204\n",
      "\n",
      "    accuracy                          0.724       816\n",
      "   macro avg      0.733     0.724     0.724       816\n",
      "weighted avg      0.733     0.724     0.724       816\n",
      "\n",
      "\n",
      "üîÅ Entra√Ænement des GMMs avec 32 composantes...\n",
      "üìä √âvaluation sur la validation :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   allemande      0.726     0.817     0.769       104\n",
      "    francais      0.919     0.654     0.764       104\n",
      "     italien      0.776     0.798     0.787       104\n",
      "       russe      0.712     0.808     0.757       104\n",
      "\n",
      "    accuracy                          0.769       416\n",
      "   macro avg      0.783     0.769     0.769       416\n",
      "weighted avg      0.783     0.769     0.769       416\n",
      "\n",
      "üìä √âvaluation sur le test :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   allemande      0.677     0.779     0.724       204\n",
      "    francais      0.864     0.623     0.724       204\n",
      "     italien      0.743     0.794     0.768       204\n",
      "       russe      0.769     0.814     0.790       204\n",
      "\n",
      "    accuracy                          0.752       816\n",
      "   macro avg      0.763     0.752     0.752       816\n",
      "weighted avg      0.763     0.752     0.752       816\n",
      "\n",
      "\n",
      "üîÅ Entra√Ænement des GMMs avec 64 composantes...\n",
      "üìä √âvaluation sur la validation :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   allemande      0.710     0.846     0.772       104\n",
      "    francais      0.875     0.740     0.802       104\n",
      "     italien      0.837     0.788     0.812       104\n",
      "       russe      0.811     0.827     0.819       104\n",
      "\n",
      "    accuracy                          0.800       416\n",
      "   macro avg      0.808     0.800     0.801       416\n",
      "weighted avg      0.808     0.800     0.801       416\n",
      "\n",
      "üìä √âvaluation sur le test :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   allemande      0.727     0.824     0.772       204\n",
      "    francais      0.892     0.686     0.776       204\n",
      "     italien      0.751     0.843     0.794       204\n",
      "       russe      0.829     0.809     0.819       204\n",
      "\n",
      "    accuracy                          0.790       816\n",
      "   macro avg      0.800     0.790     0.790       816\n",
      "weighted avg      0.800     0.790     0.790       816\n",
      "\n",
      "\n",
      "üîÅ Entra√Ænement des GMMs avec 128 composantes...\n",
      "üìä √âvaluation sur la validation :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   allemande      0.726     0.817     0.769       104\n",
      "    francais      0.902     0.798     0.847       104\n",
      "     italien      0.793     0.846     0.819       104\n",
      "       russe      0.854     0.788     0.820       104\n",
      "\n",
      "    accuracy                          0.812       416\n",
      "   macro avg      0.819     0.812     0.814       416\n",
      "weighted avg      0.819     0.812     0.814       416\n",
      "\n",
      "üìä √âvaluation sur le test :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   allemande      0.719     0.853     0.780       204\n",
      "    francais      0.916     0.745     0.822       204\n",
      "     italien      0.801     0.848     0.824       204\n",
      "       russe      0.859     0.809     0.833       204\n",
      "\n",
      "    accuracy                          0.814       816\n",
      "   macro avg      0.824     0.814     0.815       816\n",
      "weighted avg      0.824     0.814     0.815       816\n",
      "\n",
      "\n",
      "üîÅ Entra√Ænement des GMMs avec 256 composantes...\n",
      "üìä √âvaluation sur la validation :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   allemande      0.721     0.846     0.779       104\n",
      "    francais      0.912     0.798     0.851       104\n",
      "     italien      0.811     0.865     0.837       104\n",
      "       russe      0.880     0.779     0.827       104\n",
      "\n",
      "    accuracy                          0.822       416\n",
      "   macro avg      0.831     0.822     0.823       416\n",
      "weighted avg      0.831     0.822     0.823       416\n",
      "\n",
      "üìä √âvaluation sur le test :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   allemande      0.767     0.887     0.823       204\n",
      "    francais      0.957     0.760     0.847       204\n",
      "     italien      0.819     0.907     0.860       204\n",
      "       russe      0.917     0.863     0.889       204\n",
      "\n",
      "    accuracy                          0.854       816\n",
      "   macro avg      0.865     0.854     0.855       816\n",
      "weighted avg      0.865     0.854     0.855       816\n",
      "\n",
      "\n",
      "üîÅ Entra√Ænement des GMMs avec 512 composantes...\n",
      "üìä √âvaluation sur la validation :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   allemande      0.769     0.865     0.814       104\n",
      "    francais      0.924     0.817     0.867       104\n",
      "     italien      0.805     0.875     0.839       104\n",
      "       russe      0.915     0.827     0.869       104\n",
      "\n",
      "    accuracy                          0.846       416\n",
      "   macro avg      0.853     0.846     0.847       416\n",
      "weighted avg      0.853     0.846     0.847       416\n",
      "\n",
      "üìä √âvaluation sur le test :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   allemande      0.766     0.897     0.826       204\n",
      "    francais      0.964     0.779     0.862       204\n",
      "     italien      0.817     0.897     0.855       204\n",
      "       russe      0.936     0.863     0.898       204\n",
      "\n",
      "    accuracy                          0.859       816\n",
      "   macro avg      0.871     0.859     0.860       816\n",
      "weighted avg      0.871     0.859     0.860       816\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n_components in [8, 16, 32, 64, 128, 256, 512]:\n",
    "    print(f\"\\nüîÅ Entra√Ænement des GMMs avec {n_components} composantes...\")\n",
    "    models = train_gmm_models(X_train, y_train, n_components)\n",
    "\n",
    "    print(\"üìä √âvaluation sur la validation :\")\n",
    "    y_val_pred = predict(models, X_val)\n",
    "    print(classification_report(y_val, y_val_pred, digits=3))\n",
    "\n",
    "    print(\"üìä √âvaluation sur le test :\")\n",
    "    y_test_pred = predict(models, X_test)\n",
    "    print(classification_report(y_test, y_test_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mod√®le francais sauvegard√© dans models_gmm/\n",
      "‚úÖ Mod√®le italien sauvegard√© dans models_gmm/\n",
      "‚úÖ Mod√®le allemande sauvegard√© dans models_gmm/\n",
      "‚úÖ Mod√®le russe sauvegard√© dans models_gmm/\n"
     ]
    }
   ],
   "source": [
    "# Suppose que tu as d√©j√† : X_train, y_train\n",
    "models = train_gmm_models(X_train, y_train, n_components=512)  # ou 32, 64, etc.\n",
    "save_gmm_models(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-whisper\n",
      "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
      "     ---------------------------------------- 0.0/803.2 kB ? eta -:--:--\n",
      "     ------------- -------------------------- 262.1/803.2 kB ? eta -:--:--\n",
      "     ------------------------ ------------- 524.3/803.2 kB 2.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- 803.2/803.2 kB 1.9 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: more-itertools in c:\\users\\jamil\\anaconda3\\lib\\site-packages (from openai-whisper) (10.3.0)\n",
      "Requirement already satisfied: numba in c:\\users\\jamil\\anaconda3\\lib\\site-packages (from openai-whisper) (0.60.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\jamil\\anaconda3\\lib\\site-packages (from openai-whisper) (1.26.4)\n",
      "Collecting tiktoken (from openai-whisper)\n",
      "  Downloading tiktoken-0.11.0-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\jamil\\anaconda3\\lib\\site-packages (from openai-whisper) (2.5.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jamil\\anaconda3\\lib\\site-packages (from openai-whisper) (4.66.5)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\jamil\\anaconda3\\lib\\site-packages (from numba->openai-whisper) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\jamil\\anaconda3\\lib\\site-packages (from tiktoken->openai-whisper) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\jamil\\anaconda3\\lib\\site-packages (from tiktoken->openai-whisper) (2.32.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\jamil\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\jamil\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (4.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jamil\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\jamil\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\jamil\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jamil\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jamil\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (2024.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jamil\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jamil\\anaconda3\\lib\\site-packages (from tqdm->openai-whisper) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jamil\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jamil\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jamil\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jamil\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.4.26)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jamil\\anaconda3\\lib\\site-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
      "Downloading tiktoken-0.11.0-cp312-cp312-win_amd64.whl (884 kB)\n",
      "   ---------------------------------------- 0.0/884.3 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 524.3/884.3 kB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 884.3/884.3 kB 1.9 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml): started\n",
      "  Building wheel for openai-whisper (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=804013 sha256=a7865c430ec5db8b5d6a6038bee5f0c775f77311d267634862f63f3ccf9286b5\n",
      "  Stored in directory: c:\\users\\jamil\\appdata\\local\\pip\\cache\\wheels\\61\\d2\\20\\09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: tiktoken, openai-whisper\n",
      "Successfully installed openai-whisper-20250625 tiktoken-0.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U openai-whisper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
